{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75c82371-3cb1-4d76-8e9c-532fab042ea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T13:59:51.102159Z",
     "iopub.status.busy": "2024-06-30T13:59:51.101748Z",
     "iopub.status.idle": "2024-06-30T13:59:51.113733Z",
     "shell.execute_reply": "2024-06-30T13:59:51.113287Z",
     "shell.execute_reply.started": "2024-06-30T13:59:51.102141Z"
    }
   },
   "outputs": [],
   "source": [
    "from py4j.java_gateway import java_import\n",
    "from pyspark.sql import SparkSession\n",
    "from urllib.parse import urlparse\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import col, struct, upper, to_date, from_unixtime, count, sum, lit, collect_list, when, first, udf\n",
    "from pyspark.sql.types import IntegerType, LongType, FloatType, DoubleType, StringType, ArrayType\n",
    "\n",
    "\n",
    "def get_files(path, size=-1):\n",
    "    sc = spark.sparkContext\n",
    "    java_path = sc._jvm.java.net.URI.create(path)\n",
    "    hadoop_path = sc._jvm.org.apache.hadoop.fs.Path(path)\n",
    "    fs = sc._jvm.org.apache.hadoop.fs.FileSystem.get(java_path, sc._jsc.hadoopConfiguration())\n",
    "    file_statuses = fs.listStatus(sc._jvm.org.apache.hadoop.fs.Path(path))\n",
    "    \n",
    "    # Convert Java array to Python list and sort by modification time\n",
    "    sorted_files = sorted(file_statuses, key=lambda x: x.getModificationTime())\n",
    "    \n",
    "    # Using Python list operations to mimic Scala foldLeft\n",
    "    result_list = []\n",
    "    remaining_capacity = size\n",
    "    \n",
    "    for file_status in sorted_files:\n",
    "        if remaining_capacity - file_status.getLen() > 0 or size == -1:\n",
    "            if not file_status.getPath().getName().endswith(\".tmp\"):\n",
    "                result_list.append(file_status.getPath().toString())\n",
    "                remaining_capacity -= file_status.getLen()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "def move_files_to_processed(files):\n",
    "    sc = spark.sparkContext\n",
    "    path = \"s3a://intent-raw\"\n",
    "    java_path = sc._jvm.java.net.URI.create(path)\n",
    "    hadoop_path = sc._jvm.org.apache.hadoop.fs.Path(path)\n",
    "    fs = sc._jvm.org.apache.hadoop.fs.FileSystem.get(java_path, sc._jsc.hadoopConfiguration())\n",
    "    \n",
    "    for file in files:\n",
    "        path = sc._jvm.org.apache.hadoop.fs.Path(file)\n",
    "        if fs.delete(path, False):\n",
    "            print(f\"Deleted {file}\")\n",
    "        else:\n",
    "            print(f\"Failed to delete {file}\")\n",
    "\n",
    "# Define UDFs for different data types\n",
    "ns_int = udf(lambda v: None if v == 0 else v, IntegerType())\n",
    "ns_long = udf(lambda v: None if v == 0 else v, LongType())\n",
    "ns_float = udf(lambda v: None if v == 0 else v, FloatType())\n",
    "ns_double = udf(lambda v: None if v == 0 else v, DoubleType())\n",
    "ns_string = udf(lambda v: None if v == \"\" else v, StringType())\n",
    "\n",
    "# UDF for calculating session lengths\n",
    "def session_lengths(arr, dist):\n",
    "    if arr is None:\n",
    "        return []\n",
    "    \n",
    "    arr_sorted = sorted(arr)\n",
    "    groups = []\n",
    "    current_group = [arr_sorted[0]]\n",
    "    \n",
    "    for elem in arr_sorted[1:]:\n",
    "        if elem - current_group[0] < dist:\n",
    "            current_group.append(elem)\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [elem]\n",
    "    \n",
    "    groups.append(current_group)\n",
    "    \n",
    "    return [max(group) - min(group) for group in groups]\n",
    "\n",
    "# UDF for calculating engaged sessions\n",
    "def engaged_sessions(arr, minimum):\n",
    "    if arr is None:\n",
    "        return 0\n",
    "    \n",
    "    return len([session for session in arr if session >= minimum])\n",
    "\n",
    "# UDF for calculating bounced sessions\n",
    "def bounced_sessions(arr, minimum):\n",
    "    if arr is None:\n",
    "        return 0\n",
    "    \n",
    "    return len([session for session in arr if session < minimum])\n",
    "\n",
    "# UDF for calculating total time on site\n",
    "def time_on_site(arr):\n",
    "    if arr is None:\n",
    "        return 0\n",
    "    \n",
    "    return sum(arr)\n",
    "\n",
    "# Register UDFs with Spark\n",
    "session_lengths_udf = udf(session_lengths, ArrayType(LongType()))\n",
    "engaged_sessions_udf = udf(engaged_sessions, LongType())\n",
    "bounced_sessions_udf = udf(bounced_sessions, LongType())\n",
    "time_on_site_udf = udf(time_on_site, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fafb94c-d981-4c24-a146-6bbe5991fc4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for prefix in [\"auction\", \"lose\", \"win\", \"impression\", \"click\"]:\n",
    "    print(prefix)\n",
    "    rtbEntity = get_files(f\"s3a://intent-raw/new_rtb_{prefix}/\", 50000000000)\n",
    "    entity = spark.read. \\\n",
    "    json(rtbEntity). \\\n",
    "    select(\n",
    "      col(\"id\"),\n",
    "      struct(\n",
    "        ns_string(col(\"publisher.id\")).alias(\"id\"),\n",
    "        ns_string(col(\"publisher.category\")).alias(\"category\"),\n",
    "        ns_string(col(\"publisher.site\")).alias(\"site\"),\n",
    "        ns_string(col(\"publisher.language\")).alias(\"language\"),\n",
    "        ns_string(col(\"publisher.app\")).alias(\"app\"),\n",
    "        ns_string(upper(col(\"publisher.country\"))).alias(\"country\"),\n",
    "      ).alias(\"publisher\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"user.telco_id\")).alias(\"telco_id\"),\n",
    "        ns_string(col(\"user.intent_id\")).alias(\"intent_id\"),\n",
    "        ns_string(col(\"user.ad_exchange_user_id\")).alias(\"ad_exchange_user_id\"),\n",
    "        col(\"profile\")\n",
    "      ).alias(\"user\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"device.ifa\")).alias(\"ifa\"),\n",
    "        ns_string(col(\"device.make\")).alias(\"make\"),\n",
    "        ns_string(col(\"device.model\")).alias(\"model\"),\n",
    "        ns_string(col(\"device.os_name\")).alias(\"os_name\"),\n",
    "        ns_string(col(\"device.os_version\")).alias(\"os_version\"),\n",
    "        ns_string(col(\"device.connection_type\")).alias(\"connection_type\"),\n",
    "        ns_string(col(\"device.carrier\")).alias(\"carrier\"),\n",
    "        ns_string(col(\"device.language\")).alias(\"language\"),\n",
    "      ).alias(\"device\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"geo.country\")).alias(\"country\"),\n",
    "        ns_string(col(\"geo.region\")).alias(\"region\"),\n",
    "        ns_string(col(\"geo.city\")).alias(\"city\"),\n",
    "        ns_long(col(\"geo.utc_offset\")).alias(\"utc_offset\")\n",
    "      ).alias(\"geo\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"advertiser.id\")).alias(\"id\"),\n",
    "        ns_string(col(\"advertiser.name\")).alias(\"name\"),\n",
    "        ns_string(col(\"advertiser.currency\")).alias(\"currency\"),\n",
    "        ns_double(col(\"advertiser.spend\")).alias(\"spend\"),\n",
    "        ns_double(col(\"advertiser.spend_usd\")).alias(\"spend_usd\"),\n",
    "      ).alias(\"advertiser\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"campaign.id\")).alias(\"id\"),\n",
    "        ns_string(col(\"campaign.name\")).alias(\"name\"),\n",
    "        col(\"campaign.categories\"),\n",
    "        ns_string(col(\"campaign.optimization_type\")).alias(\"optimization_type\"),\n",
    "        ns_double(col(\"campaign.user_cpx\")).alias(\"user_cpx\"),\n",
    "        ns_double(col(\"campaign.cpx\")).alias(\"cpx\"),\n",
    "      ).alias(\"campaign\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"creative.id\")).alias(\"id\"),\n",
    "        ns_string(col(\"creative.format\")).alias(\"format\"),\n",
    "        ns_long(col(\"creative.height\")).alias(\"height\"),\n",
    "        ns_long(col(\"creative.width\")).alias(\"width\")\n",
    "      ).alias(\"creative\"),\n",
    "    \n",
    "      struct(\n",
    "        col(\"placement.postition\").alias(\"position\"),\n",
    "        col(\"placement.is_interstitial\")).alias(\"is_interstitial\"),\n",
    "        col(\"placement.is_rewarded\")).alias(\"is_rewarded\"),\n",
    "        col(\"placement.video_minduration\")).alias(\"video_minduration\"),\n",
    "        col(\"placement.video_maxduration\")).alias(\"video_maxduration\"),\n",
    "        col(\"placement.video_startdelay\")).alias(\"video_startdelay\"),\n",
    "        col(\"placement.video_placement\")).alias(\"video_placement\"),\n",
    "        ns_long(col(\"placement.height\")).alias(\"height\"),\n",
    "        ns_long(col(\"placement.width\")).alias(\"width\"),\n",
    "      ).alias(\"placement\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"model.notelco_model_name\")).alias(\"notelco_model_name\"),\n",
    "        ns_string(col(\"model.notelco_model_version\")).alias(\"notelco_model_version\"),\n",
    "        ns_string(col(\"model.notelco_run_id\")).alias(\"notelco_run_id\"),\n",
    "        ns_double(col(\"model.notelco_model_probability_cc\")).alias(\"notelco_model_probability_cc\"),\n",
    "        ns_double(col(\"model.notelco_model_probability_sc\")).alias(\"notelco_model_probability_sc\"),\n",
    "        ns_double(col(\"model.notelco_model_probability_final\")).alias(\"notelco_model_probability_final\"),\n",
    "        # ns_string(col(\"model.telco_model_name\")).alias(\"telco_model_name\"),\n",
    "        # ns_string(col(\"model.telco_model_version\")).alias(\"telco_model_version\"),\n",
    "        # ns_string(col(\"model.telco_run_id\")).alias(\"telco_run_id\"),\n",
    "        ns_string(col(\"model.win_model_name\")).alias(\"win_model_name\"),\n",
    "        ns_string(col(\"model.win_model_version\")).alias(\"win_model_version\"),\n",
    "        ns_string(col(\"model.win_run_id\")).alias(\"win_run_id\"),\n",
    "        ns_double(col(\"model.win_model_probability\")).alias(\"win_model_probability\"),\n",
    "        ns_double(col(\"model.win_model_lambda\")).alias(\"win_model_lambda\")\n",
    "      ).alias(\"model\"),\n",
    "    \n",
    "      struct(\n",
    "        ns_string(col(\"bid.request_id\")).alias(\"request_id\"),\n",
    "        col(\"bid.bid_index\")).alias(\"bid_index\"),\n",
    "        ns_double(col(\"bid.bid_price\")).alias(\"bid_price\"),\n",
    "        ns_double(col(\"bid.win_price\")).alias(\"win_price\"),\n",
    "        ns_double(col(\"bid.second_price\")).alias(\"second_price\"),\n",
    "        ns_double(col(\"bid.spend\")).alias(\"spend\"),\n",
    "        ns_double(col(\"bid.bid_floor\")).alias(\"bid_floor\"),\n",
    "        ns_string(col(\"bid.exchange_id\")).alias(\"exchange_id\"),\n",
    "        col(\"bid.time\"),\n",
    "        col(\"bid.loss_reason_code\"),\n",
    "        ns_double(col(\"bid.currency_rate\")).alias(\"currency_rate\"),\n",
    "        ns_string(col(\"bid.displaymanager\")).alias(\"displaymanager\"),\n",
    "      ).alias(\"bid\"),\n",
    "    \n",
    "      col(\"time\")).alias(\"time\")\n",
    "    ). \\\n",
    "    withColumn(\"date\", to_date(from_unixtime(col(\"time\"))).cast(\"string\"))\n",
    "    \n",
    "    entity. \\\n",
    "    repartition(12). \\\n",
    "    write.format(\"delta\")). \\\n",
    "    partitionBy(\"date\")).mode(\"Append\")).option(\"mergeSchema\", True). \\\n",
    "    save(f\"s3a://intent-parquet/rtb_{prefix}\")\n",
    "    \n",
    "    move_files_to_processed(rtbEntity)\n",
    "\n",
    "rtbEventFiles = get_files(f\"s3a://intent-raw/new_rtb_event/\")\n",
    "\n",
    "spark.read. \\\n",
    "json(rtbEventFiles). \\\n",
    "withColumn(\"date\", to_date(from_unixtime(col(\"timestamp\")))). \\\n",
    "repartition(12). \\\n",
    "write.format(\"delta\")). \\\n",
    "partitionBy(\"date\")).mode(\"Append\")).option(\"mergeSchema\", True). \\\n",
    "save(f\"s3a://intent-parquet/rtb_event\")\n",
    "\n",
    "move_files_to_processed(rtbEventFiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark L cluster",
   "language": "",
   "name": "pyspark-l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
